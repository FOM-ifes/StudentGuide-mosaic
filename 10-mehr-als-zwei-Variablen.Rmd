# Mehr als zwei Variablen {#mehrVars}

## Zwei- (oder mehr-) faktorielle ANOVA

Wir können ein zwei- (oder mehr-) faktorielles ANOVA-Modell, mit oder ohne Interaktion, auf Basis der vereinheitlichten `mosaic`-Syntax erstellen.

```{r}
HELPrct <- mutate(HELPrct, 
                  subgrp = factor(substance,
                                  levels = c("alcohol", "cocaine","heroine"),
                                  labels = c("A", "C", "H"))
                  )
median(cesd ~ substance | sex, data = HELPrct)
gf_boxplot(cesd ~ subgrp | sex, data = HELPrct)
summary(aov(cesd ~ substance + sex, data=HELPrct))
summary(aov(cesd ~ substance * sex, data=HELPrct))
```

Es deutet wenig auf eine Interaktion hin, obwohl signifikante Haupteffekte für die option `Substanzgruppen` und option `sex` bestehen.

```{r}
mod <- lm(cesd ~ substance + sex + substance * sex, data = HELPrct)
plotModel(mod)
```

## Multiple Regression
Multiple Regression ist eine logische Erweiterung der vorangegangenen Befehle, sobald zusätzliche Prädiktoren hinzukommen. Dies ermöglicht es den Studierenden mit dem Versuch zu beginnen, multivariate Beziehungen zu entflechten.

:::{.note data-latex=""}
Wir neigen dazu, multiple lineare Regression zeitig in unseren Kurse einzuführen, als eine rein deskriptive Methode, und dann immer wieder zu ihr zurückzukehren. Die Beweggründe werden ausführlich im Begleitmaterial *Start Modeling with R* [@ModelingR] beschrieben
:::

Hier betrachten wir ein Modell (Parallelsteigungen) für die depressive Symptomatik als eine Funktion aus dem Mental Component Score (MCS), dem Alter (in Jahren) und dem Geschlecht der Person.

```{r}
lmnointeract <- lm(cesd~mcs+age+sex,data=HELPrct)
msummary(lmnointeract)
```

Wir können ebenso ein Modell anpassen, das eine Interaktion zwischen `MCS` und `sex` einschließt.

```{r}
lminteract <- lm(cesd ~ mcs + age + sex + mcs:sex, data= HELPrct)
msummary(lminteract)

anova(lminteract)

anova(lmnointeract, lminteract)
```

Es deutet wenig auf einen Interaktionseffekt hin, sodass wir diese aus dem Modell entfernen können.


### Visualisierung der Regressionsergebnisse {#VisReg}

Die Funktionen `makeFun()` und `plotFun()`aus dem Paket `mosaic` können zur Abbildung der vorhergesagten Werte des Regressionsmodells verwendet werden. Für dieses Beispiel könnten wir die vorhergesagten CESD-Werte für einen MCS-Wertebereich (mental component score) ausgeben, die eine hypothetisch 36-jährige männliche und weibliche Person in einem Modell mit parallelen Steigungen (keine Interaktion) haben könnte.

```{r}
lmfunction <- makeFun(lmnointeract)
```

Wir können nun die vorhergesagten Werte - getrennt nach männlichen und weiblichen Personen - für einen MCS-Wertebereich (mental component score), zusammen mit den beobachteten Werten aller 36-jähriger darstellen.

```{r}
gf_point(cesd ~ mcs, color = ~ sex,
         data = filter(HELPrct, age == 36),
         ylab = "vorhergesagte CESD") %>%
gf_fun(lmfunction(mcs, age=36, sex = "male") ~ mcs,
       xlim = c(0,60), size = 1.5) %>%
gf_fun(lmfunction(mcs, age=36, sex = "female") ~ mcs,
       xlim = c(0,60), linetype = 2, size = 2)
```


### Koeffizientendarstellung

Manchmal ist es nützlich eine Darstellung der Koeffizienten eines multiplen Regressionsmodells (zusammen mit den entsprechenden Konfidenzintervallen) zu erstellen.

```{r}
mplot(lmnointeract, rows = -1, which = 7)
```

:::{.note data-latex=""}
Dunklere bzw. hier die blauen Punkte weisen auf Regressionskoeffizienten hin, bei denen das 95%-Konfidenzinterval nicht den Wert Null der Nullhypothese beinhaltet.
:::

:::{.achtung data-latex=""}
Vorsicht bei der Generierung eines Regressionsmodells, bei Vorliegen von fehlenden Werten (siehe Abschnitt \@ref(missings))
:::


### Auswertung der Residuen

Es ist recht einfach die Residuen des Modells auszuwerten. Wir beginnen damit, die angepassten Werte und die Residuen den Daten hinzuzufügen.

:::{.hinweis data-latex=""}
Die Funktion `mplot()` kann ebenfalls zur Erstellung dieser Grafiken verwendet werden.
:::

:::{.note data-latex=""}
Hier fügen wir zwei neue Variabelen zu einem bestehenden Datensatz hinzu. Es ist häufig eine gute Programmierpraxis, dem daraus resultierenden Datensatz einen neuen Namen zu geben. Für dieses Dokument behalten wir den Namen allerdings der Einfachheit halber bei.
:::

```{r}
HELPrct <- mutate(HELPrct, 
                  residuals = resid(lmnointeract), 
                  pred = fitted(lmnointeract))
gf_dhistogram(~ residuals, data= HELPrct) %>%
  gf_fitdistr(dist = "dnorm")
```

Wir können den Teil der Beobachtungen mit extrem hohen Residuen bestimmen.

```{r, tidy=FALSE}
filter(HELPrct, abs(residuals)>25)

gf_point(residuals ~ pred, cex = .3, xlab = "Vorhergesagte Werte",
         title = "Vorhergesagte vs. Residuen", data = HELPrct) %>%
  gf_smooth(se = FALSE) %>% 
  gf_hline(yintercept = 0)

gf_point(residuals ~ mcs, cex = .3, xlab = "Mentalitätskomponentenwert",
         title = "Vorhergesagte vs. Residuen", data = HELPrct) %>%
  gf_smooth(se = FALSE) %>%
  gf_hline(yintercept = 0)
```

Die Annahme der Normalverteilungs- (s. Histogramm), Linearitäts-, und Heteroskedazitätsvoraussetzung (s. Residuenplots - jeweils eine horizontale Linie ohne Muster oder Trends in der Punktewolke) erscheint hier vernünftig.

